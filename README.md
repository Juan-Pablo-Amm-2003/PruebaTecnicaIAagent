

# üìò Agno + FastAPI + Azure AI Foundry ‚Äî Backend

Servicio REST en **FastAPI** que expone un **Agente Agno** en `/agent/invoke`, con **health checks** y **m√©tricas Prometheus**. Listo para desarrollo local y despliegue en contenedores.

---

## üöÄ Requisitos

```txt
- Python 3.12+
- Docker Engine / Docker Desktop (opcional)
- Credenciales Azure AI Foundry/OpenAI:
  - AZURE_OPENAI_ENDPOINT
  - AZURE_OPENAI_API_KEY
  - AZURE_OPENAI_API_VERSION
  - AZURE_OPENAI_DEPLOYMENT
```

---

## ‚öôÔ∏è Configuraci√≥n

`.env` (ejemplo):

```env
APP_NAME=pruebatecnicasancorseguros
DEBUG=false

AZURE_OPENAI_ENDPOINT=https://<tu-resource>.openai.azure.com
AZURE_OPENAI_API_KEY=<tu_api_key>
AZURE_OPENAI_API_VERSION=2024-08-01-preview
AZURE_OPENAI_DEPLOYMENT=gpt-4.1
```

---

## üíª Desarrollo local

```bash
python -m venv .venv
# Windows
.\.venv\Scripts\Activate.ps1
# Linux/Mac
source .venv/bin/activate

pip install --upgrade pip
pip install -r requirements.txt

uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

üëâ Abrir: [http://localhost:8000/docs](http://localhost:8000/docs)

---

## üê≥ Docker

`docker-compose.dev.yml`

```yaml
version: "3.9"
services:
  api:
    build: .
    image: agno-fastapi-azure:dev
    container_name: agno-fastapi-azure-dev
    env_file:
      - .env
    ports:
      - "8080:8000"
    command: >
      uvicorn app.main:app
      --host 0.0.0.0
      --port 8000
      --reload
    volumes:
      - ./:/app
    environment:
      WATCHFILES_FORCE_POLLING: "1"
```

Correr:

```bash
docker compose -f docker-compose.dev.yml up --build
```

üëâ UI: [http://localhost:8080/docs](http://localhost:8080/docs)

---

## üè≠ Producci√≥n

`Dockerfile`

```dockerfile
FROM python:3.12-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install -U pip && pip install -r requirements.txt

COPY . .

EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=3s --retries=3 \
  CMD wget -qO- http://localhost:8000/health/live || exit 1

CMD ["gunicorn", "-c", "gunicorn.conf.py", "app.main:app"]
```

`gunicorn.conf.py`

```python
import multiprocessing

bind = "0.0.0.0:8000"
workers = max(2, multiprocessing.cpu_count() // 2)
worker_class = "uvicorn.workers.UvicornWorker"
timeout = 120
keepalive = 5
```

Ejecutar en prod:

```bash
gunicorn -k uvicorn.workers.UvicornWorker app.main:app -w 2 -b 0.0.0.0:8000
```

---

## üì° Endpoints

```txt
GET /              ‚Üí redirect /docs
GET /docs          ‚Üí Swagger UI
GET /health/live   ‚Üí proceso arriba
GET /health/ready  ‚Üí dependencias OK
GET /health/azure  ‚Üí chequeo Azure
GET /metrics       ‚Üí m√©tricas Prometheus
POST /agent/invoke ‚Üí invocar agente
```

---

## üîó Ejemplo de invocaci√≥n

```bash
curl -X POST http://localhost:8000/agent/invoke \
  -H "Content-Type: application/json" \
  -d '{ "message": "ping", "temperature": 0.2 }'
```





